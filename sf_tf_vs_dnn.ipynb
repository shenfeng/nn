{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import Optional, Tuple\n",
    "from dataclasses import dataclass\n",
    "torch.set_printoptions(sci_mode=False, precision=4)\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class ModelArgs:\n",
    "    n_embd: int = 32\n",
    "    n_layer: int = 2\n",
    "    n_head: int = 2\n",
    "    vocab_size: int = -1  # defined later by tokenizer\n",
    "\n",
    "    bias: bool = False\n",
    "    dropout: float = 0.1\n",
    "\n",
    "    batch_size: int = 32\n",
    "    max_seq_len: int = 2048\n",
    "    dtype: torch.dtype = torch.float32\n",
    "\n",
    "    rotary: bool = True\n",
    "    device: str = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "    def __init__(self):\n",
    "        if torch.cuda.is_available():\n",
    "            self.dtype = torch.bfloat16\n",
    "            self.n_embd = 128\n",
    "            self.n_head = 4\n",
    "            self.n_layer = 6\n",
    "\n",
    "config = ModelArgs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/meta-llama/llama/blob/llama_v2/llama/model.py\n",
    "\n",
    "def precompute_freqs_cis(dim: int, end: int, theta: float = 10000.0):\n",
    "    \"\"\"\n",
    "    Precompute the frequency tensor for complex exponentials (cis) with given dimensions.\n",
    "\n",
    "    This function calculates a frequency tensor with complex exponentials using the given dimension 'dim'\n",
    "    and the end index 'end'. The 'theta' parameter scales the frequencies.\n",
    "    The returned tensor contains complex values in complex64 data type.\n",
    "\n",
    "    Args:\n",
    "        dim (int): Dimension of the frequency tensor.\n",
    "        end (int): End index for precomputing frequencies.\n",
    "        theta (float, optional): Scaling factor for frequency computation. Defaults to 10000.0.\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: Precomputed frequency tensor with complex exponentials.\n",
    "    \"\"\"\n",
    "    freqs = 1.0 / (theta ** (torch.arange(0, dim, 2)[: (dim // 2)].float() / dim))\n",
    "    t = torch.arange(end, device=freqs.device)  # type: ignore\n",
    "    freqs = torch.outer(t, freqs).float()  # type: ignore\n",
    "    freqs_cis = torch.polar(torch.ones_like(freqs), freqs)  # complex64\n",
    "    return freqs_cis\n",
    "\n",
    "\n",
    "def reshape_for_broadcast(freqs_cis: torch.Tensor, x: torch.Tensor):\n",
    "    \"\"\"\n",
    "    Reshape frequency tensor for broadcasting it with another tensor.\n",
    "\n",
    "    This function reshapes the frequency tensor to have the same shape as the target tensor 'x'\n",
    "    for the purpose of broadcasting the frequency tensor during element-wise operations.\n",
    "\n",
    "    Args:\n",
    "        freqs_cis (torch.Tensor): Frequency tensor to be reshaped.\n",
    "        x (torch.Tensor): Target tensor for broadcasting compatibility.\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: Reshaped frequency tensor.\n",
    "\n",
    "    Raises:\n",
    "        AssertionError: If the frequency tensor doesn't match the expected shape.\n",
    "        AssertionError: If the target tensor 'x' doesn't have the expected number of dimensions.\n",
    "    \"\"\"\n",
    "    ndim = x.ndim\n",
    "    assert 0 <= 1 < ndim\n",
    "    assert freqs_cis.shape == (x.shape[1], x.shape[-1])\n",
    "    shape = [d if i == 1 or i == ndim - 1 else 1 for i, d in enumerate(x.shape)]\n",
    "    return freqs_cis.view(*shape)\n",
    "\n",
    "\n",
    "def apply_rotary_emb(xq: torch.Tensor, xk: torch.Tensor, freqs_cis: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "    \"\"\"\n",
    "    Apply rotary embeddings to input tensors using the given frequency tensor.\n",
    "\n",
    "    This function applies rotary embeddings to the given query 'xq' and key 'xk' tensors using the provided\n",
    "    frequency tensor 'freqs_cis'. The input tensors are reshaped as complex numbers, and the frequency tensor\n",
    "    is reshaped for broadcasting compatibility. The resulting tensors contain rotary embeddings and are\n",
    "    returned as real tensors.\n",
    "\n",
    "    Args:\n",
    "        xq (torch.Tensor): Query tensor to apply rotary embeddings.\n",
    "        xk (torch.Tensor): Key tensor to apply rotary embeddings.\n",
    "        freqs_cis (torch.Tensor): Precomputed frequency tensor for complex exponentials.\n",
    "\n",
    "    Returns:\n",
    "        Tuple[torch.Tensor, torch.Tensor]: Tuple of modified query tensor and key tensor with rotary embeddings.\n",
    "        \n",
    "    \"\"\"\n",
    "    xq_ = torch.view_as_complex(xq.float().reshape(*xq.shape[:-1], -1, 2))\n",
    "    xk_ = torch.view_as_complex(xk.float().reshape(*xk.shape[:-1], -1, 2))\n",
    "    freqs_cis = reshape_for_broadcast(freqs_cis, xq_)\n",
    "    xq_out = torch.view_as_real(xq_ * freqs_cis).flatten(3)\n",
    "    xk_out = torch.view_as_real(xk_ * freqs_cis).flatten(3)\n",
    "    return xq_out.type_as(xq), xk_out.type_as(xk)\n",
    "\n",
    "class CausalSelfAttention(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        assert config.n_embd % config.n_head == 0\n",
    "        # key, query, value projections for all heads, but in a batch\n",
    "        self.c_attn = nn.Linear(config.n_embd, 3 * config.n_embd, bias=config.bias, dtype=config.dtype, device=config.device)\n",
    "        # output projection\n",
    "        # self.c_proj = nn.Linear(config.n_embd, config.n_embd, bias=config.bias, dtype=config.dtype, device=config.device)\n",
    "        # regularization\n",
    "        # self.attn_dropout = nn.Dropout(config.dropout)\n",
    "        # self.resid_dropout = nn.Dropout(config.dropout)\n",
    "        self.n_head = config.n_head\n",
    "        self.n_embd = config.n_embd\n",
    "        self.dropout = config.dropout\n",
    "        self.is_causal = False\n",
    "\n",
    "    def forward(self, x, freqs_cis):\n",
    "        B, T, C = x.size()  # batch size, sequence length, embedding dimensionality (n_embd)\n",
    "\n",
    "        # calculate query, key, values for all heads in batch and move head forward to be the batch dim\n",
    "        q, k, v = self.c_attn(x).split(self.n_embd, dim=2)\n",
    "        k = k.view(B, T, self.n_head, C // self.n_head)\n",
    "        q = q.view(B, T, self.n_head, C // self.n_head)\n",
    "        v = v.view(B, T, self.n_head, C // self.n_head).transpose(1, 2)  # (B, nh, T, hs)\n",
    "\n",
    "        if freqs_cis is not None:\n",
    "            q, k = apply_rotary_emb(q, k, freqs_cis=freqs_cis)\n",
    "\n",
    "        q = q.transpose(1, 2)  # (B, nh, T, hs)\n",
    "        k = k.transpose(1, 2)  # (B, nh, T, hs)\n",
    "\n",
    "        # causal self-attention; Self-attend: (B, nh, T, hs) x (B, nh, hs, T) -> (B, nh, T, T)\n",
    "        # efficient attention using Flash Attention CUDA kernels\n",
    "        y = F.scaled_dot_product_attention(q, k, v, attn_mask=None,\n",
    "                                           dropout_p=self.dropout if self.training else 0, is_causal=self.is_causal)\n",
    "        y = y.transpose(1, 2).contiguous().view(B, T, C)  # re-assemble all head outputs side by side\n",
    "\n",
    "        # output projection\n",
    "        # y = self.resid_dropout(self.c_proj(y))\n",
    "        return y\n",
    "\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.c_fc    = nn.Linear(config.n_embd, 4 * config.n_embd, bias=config.bias, dtype=config.dtype, device=config.device)\n",
    "        self.gelu    = nn.GELU()\n",
    "        self.c_proj  = nn.Linear(4 * config.n_embd, config.n_embd, bias=config.bias, dtype=config.dtype, device=config.device)\n",
    "        self.dropout = nn.Dropout(config.dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.c_fc(x)\n",
    "        x = self.gelu(x)\n",
    "        x = self.c_proj(x)\n",
    "        x = self.dropout(x)\n",
    "        return x\n",
    "\n",
    "class Block(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.rmsn_1 = nn.RMSNorm(config.n_embd, device=config.device, dtype=config.dtype)\n",
    "        self.attn = CausalSelfAttention(config)\n",
    "        self.rmsn_2 = nn.RMSNorm(config.n_embd, device=config.device, dtype=config.dtype)\n",
    "        self.mlp = MLP(config)\n",
    "\n",
    "    def forward(self, x, freqs_cis):\n",
    "        x = x + self.attn(self.rmsn_1(x), freqs_cis)\n",
    "        x = x + self.mlp(self.rmsn_2(x))\n",
    "        return x\n",
    "\n",
    "class GPT(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "        self.wte=nn.Embedding(config.vocab_size, config.n_embd, dtype=config.dtype, device=config.device)\n",
    "        self.h =nn.ModuleList([Block(config) for _ in range(config.n_layer)])         \n",
    "        self.lm_head = nn.Linear(config.n_embd, config.vocab_size, bias=config.bias, dtype=config.dtype, device=config.device)\n",
    "        if config.rotary:\n",
    "            self.freqs_cis = precompute_freqs_cis(config.n_embd // config.n_head, config.max_seq_len * 2).to(config.device)\n",
    "        else:\n",
    "            self.wpe = nn.Embedding(256, config.n_embd, device=config.device, dtype=config.dtype)\n",
    "            self.pos_idx = torch.arange(0, 1024, dtype=torch.long, device=config.device)\n",
    "            self.freqs_cis = None\n",
    "\n",
    "        # self.wte.weight = self.lm_head.weight # https://paperswithcode.com/method/weight-tying\n",
    "        self.rmsn=nn.RMSNorm(config.n_embd, device=config.device, dtype=config.dtype)\n",
    "        self.apply(self._init_weights)\n",
    "\n",
    "    def _init_weights(self, module):\n",
    "        if isinstance(module, nn.Linear):\n",
    "            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
    "            if module.bias is not None:\n",
    "                torch.nn.init.zeros_(module.bias)\n",
    "        elif isinstance(module, nn.Embedding):\n",
    "            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
    "\n",
    "    def forward(self, idx, targets=None):\n",
    "        _bsz, seqlen = idx.shape\n",
    "\n",
    "        x = self.wte(idx)  # token embeddings of shape (b, t, n_embd)\n",
    "        if self.freqs_cis is None:\n",
    "            x += self.wpe(self.pos_idx[:seqlen])\n",
    "            freqs_cis = None\n",
    "        else:\n",
    "            freqs_cis = self.freqs_cis[:seqlen]\n",
    "        for block in self.h:\n",
    "            x = block(x, freqs_cis)\n",
    "        x = self.rmsn(x)\n",
    "        logits = self.lm_head(x) # B, T, vocab_size\n",
    "        logits = logits[:, -1, :]  # last one      \n",
    "        # if we are given some desired targets also calculate the loss\n",
    "        loss = None\n",
    "        if targets is not None:\n",
    "            # loss = F.cross_entropy(logits.view(-1, logits.size(-1)), targets.view(-1))\n",
    "            loss = F.cross_entropy(logits, targets)\n",
    "\n",
    "        return logits, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.4372,  0.3701,  1.5816, -0.1556],\n",
       "         [ 0.1511, -1.3495, -0.7089, -0.2434],\n",
       "         [-2.1701,  0.4161,  1.0159, -0.2136]],\n",
       "\n",
       "        [[-0.9229, -0.2264, -0.0301,  0.4067],\n",
       "         [-1.7423, -0.7882, -0.1232,  1.5986],\n",
       "         [ 0.5884,  0.6930, -0.2881,  0.6280]]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(13)\n",
    "x = torch.randn(2, 3, 4)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-2.1701,  0.4161,  1.0159, -0.2136],\n",
       "        [ 0.5884,  0.6930, -0.2881,  0.6280]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[:,-1,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.0596,  0.0568,  0.2460,  0.0706,  0.0052,  0.0270, -0.1398,\n",
       "           0.1677,  0.0867, -0.1406,  0.0380,  0.0434, -0.1751, -0.1319,\n",
       "           0.1504, -0.1324,  0.0828,  0.0459, -0.2859, -0.0450, -0.0359,\n",
       "           0.2662, -0.1456, -0.0038, -0.1007,  0.0747,  0.0604, -0.0895,\n",
       "           0.2200, -0.1594,  0.2052,  0.0279,  0.0978, -0.1103,  0.0741,\n",
       "           0.0199,  0.1176,  0.0953,  0.0800, -0.0324, -0.0179, -0.0270,\n",
       "           0.0537, -0.0115,  0.0294, -0.0514, -0.1358, -0.1006, -0.0119,\n",
       "           0.2503, -0.0704, -0.0960,  0.1120,  0.0210, -0.0770,  0.1577,\n",
       "          -0.0145, -0.0904,  0.0924, -0.1659,  0.0047,  0.0839, -0.0555,\n",
       "           0.0069],\n",
       "         [-0.1262, -0.0099, -0.0071, -0.0194, -0.0142,  0.0764,  0.0564,\n",
       "           0.0544, -0.1410, -0.0199, -0.0729, -0.1143,  0.0503,  0.1272,\n",
       "           0.1048,  0.0610, -0.0093,  0.0141, -0.1129, -0.1118, -0.1458,\n",
       "           0.0377, -0.1448,  0.1341,  0.1015,  0.0174,  0.0548, -0.1718,\n",
       "          -0.0134,  0.0361,  0.0151,  0.1809, -0.0187, -0.0811, -0.2309,\n",
       "          -0.0022, -0.0612,  0.0285, -0.0384,  0.0522,  0.0808,  0.2442,\n",
       "          -0.0880, -0.0969, -0.0869,  0.2427, -0.0511,  0.1452, -0.1004,\n",
       "          -0.1274, -0.0894, -0.0315, -0.0174,  0.1252, -0.1003, -0.0192,\n",
       "           0.1800, -0.1665, -0.0738,  0.1647,  0.0352, -0.1470, -0.1437,\n",
       "           0.1107],\n",
       "         [-0.0111, -0.0377, -0.2418, -0.0666,  0.0566, -0.0270,  0.2667,\n",
       "           0.0019, -0.1149,  0.1132, -0.0080,  0.1356,  0.0037,  0.0214,\n",
       "          -0.0389,  0.1099,  0.0508, -0.1767,  0.2202,  0.1015, -0.0690,\n",
       "           0.0555, -0.0868,  0.1614,  0.0103,  0.0380,  0.1485,  0.1089,\n",
       "          -0.0811,  0.1231, -0.0369,  0.1194,  0.0665, -0.0606, -0.2000,\n",
       "          -0.0005, -0.0070,  0.0763, -0.0960,  0.0806,  0.1816,  0.0501,\n",
       "          -0.0346, -0.0398,  0.0482,  0.1504,  0.0181,  0.0293,  0.0847,\n",
       "          -0.1658,  0.0504,  0.1580, -0.0264, -0.0770,  0.1589, -0.1259,\n",
       "          -0.1090, -0.1021, -0.0225,  0.2037,  0.0877, -0.0636,  0.1333,\n",
       "           0.0752],\n",
       "         [ 0.0830,  0.0339,  0.2939,  0.0383,  0.0113, -0.0005, -0.1117,\n",
       "           0.1285,  0.0730, -0.1930,  0.1599,  0.0619, -0.0193, -0.0739,\n",
       "           0.1187, -0.1929, -0.0026,  0.0114, -0.2769, -0.0031,  0.0003,\n",
       "           0.2197, -0.0758, -0.0106, -0.1566,  0.1223,  0.1115, -0.0878,\n",
       "           0.1316, -0.1700,  0.1248, -0.0390,  0.0649, -0.0822,  0.1491,\n",
       "          -0.0045,  0.0645,  0.0514,  0.0570, -0.0197, -0.0049, -0.1305,\n",
       "           0.1414,  0.1357, -0.0262, -0.1102, -0.0723, -0.0850, -0.0739,\n",
       "           0.1742, -0.1022, -0.0474,  0.1215,  0.0297,  0.0244,  0.1797,\n",
       "           0.0152,  0.0105,  0.0584, -0.1681, -0.0185,  0.0649, -0.0143,\n",
       "          -0.0151]],\n",
       "\n",
       "        [[-0.1429, -0.0590,  0.1000,  0.1626, -0.0906,  0.1642,  0.0433,\n",
       "           0.0937, -0.0595, -0.0876,  0.1940, -0.0695, -0.0080,  0.0176,\n",
       "           0.0526,  0.1635,  0.0307, -0.0130, -0.1965,  0.0910, -0.0855,\n",
       "          -0.0178, -0.0662,  0.0172,  0.0475, -0.0946,  0.0892, -0.2345,\n",
       "           0.1363, -0.0315,  0.0334, -0.1131,  0.0387, -0.0746,  0.1048,\n",
       "           0.1933,  0.1057, -0.0582,  0.0752, -0.1751, -0.1484,  0.0825,\n",
       "           0.1930, -0.0230, -0.1499,  0.1773, -0.0297, -0.0176, -0.0448,\n",
       "           0.0400, -0.0215, -0.0049, -0.0882,  0.0043, -0.0541, -0.0562,\n",
       "           0.2891, -0.1227,  0.0104, -0.0128,  0.1058, -0.1265,  0.0227,\n",
       "           0.0563],\n",
       "         [-0.0184, -0.0467, -0.2280, -0.0483, -0.0518,  0.0148,  0.2967,\n",
       "           0.0061, -0.1870,  0.0483,  0.1020, -0.0400, -0.0033,  0.0254,\n",
       "          -0.0298,  0.0998,  0.0993, -0.1494,  0.2061,  0.1031,  0.0180,\n",
       "           0.0954, -0.0518,  0.1976,  0.0144, -0.0880,  0.1696,  0.1394,\n",
       "           0.0016,  0.1261, -0.1753,  0.0236,  0.0728,  0.0003, -0.0766,\n",
       "           0.0564, -0.0076,  0.0111, -0.0390, -0.0012,  0.1348,  0.1415,\n",
       "           0.0944,  0.0090, -0.0319,  0.2177,  0.0418,  0.0433,  0.1109,\n",
       "          -0.1680,  0.0147,  0.1096,  0.0137, -0.1233,  0.0892, -0.0905,\n",
       "          -0.0058, -0.1551, -0.0442,  0.1498,  0.1346, -0.1323,  0.1256,\n",
       "          -0.0018],\n",
       "         [ 0.0751,  0.0703, -0.1170, -0.0286, -0.2219,  0.0740, -0.0241,\n",
       "          -0.0341,  0.0576,  0.0476,  0.0232, -0.0742, -0.2546, -0.0717,\n",
       "          -0.1816, -0.1444,  0.0008,  0.0199,  0.1713,  0.0172,  0.0384,\n",
       "          -0.0920,  0.1761,  0.0286, -0.1182, -0.1011, -0.1128,  0.2009,\n",
       "           0.0945,  0.1111, -0.0772, -0.3072, -0.2288,  0.0271,  0.1825,\n",
       "          -0.0432, -0.0603, -0.0454,  0.0474, -0.0704,  0.0466, -0.0125,\n",
       "           0.1910, -0.1321, -0.0053, -0.1476,  0.1055, -0.0253, -0.0445,\n",
       "           0.0643,  0.1932, -0.0181,  0.1314, -0.0944, -0.0053, -0.1655,\n",
       "           0.1075, -0.0407, -0.0211, -0.0728,  0.0558, -0.0747, -0.0556,\n",
       "          -0.0232],\n",
       "         [-0.1744, -0.0365,  0.1491,  0.1936, -0.1309,  0.1639, -0.0137,\n",
       "           0.0900, -0.0798, -0.1215,  0.2271, -0.1097, -0.0371,  0.1396,\n",
       "           0.0554,  0.0797,  0.0416, -0.0122, -0.1377,  0.1173,  0.0463,\n",
       "          -0.0240, -0.0336,  0.0610, -0.0553, -0.1450,  0.1423, -0.2282,\n",
       "           0.2305, -0.0434, -0.0115, -0.1500,  0.0131, -0.1231,  0.1598,\n",
       "           0.2035,  0.1151, -0.0694,  0.1137, -0.0836, -0.1667,  0.1117,\n",
       "           0.2037,  0.0484, -0.3020,  0.2072, -0.0354, -0.0280, -0.0699,\n",
       "           0.0261, -0.0628, -0.1001, -0.0453,  0.0079, -0.0549, -0.0316,\n",
       "           0.3055, -0.0331, -0.0784, -0.1321,  0.1013, -0.1184,  0.0189,\n",
       "           0.0131]]], grad_fn=<UnsafeViewBackward0>)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randint(1, 10, (2, 4))\n",
    "logits, loss = gpt(x)\n",
    "logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('input.txt', 'r', encoding='utf-8') as f:\n",
    "    text = f.read()\n",
    "# here are all the unique characters that occur in this text\n",
    "chars = sorted(list(set(text)))\n",
    "vocab_size = len(chars) + 1\n",
    "# create a mapping from characters to integers\n",
    "stoi = { ch:i + 1 for i,ch in enumerate(chars) }\n",
    "stoi['<>'] = 0\n",
    "itos = { i:ch for ch,i in stoi.items() }\n",
    "encode = lambda s: [stoi[c] for c in s] # encoder: take a string, output a list of integers\n",
    "decode = lambda l: ''.join([itos[i] for i in l]) # decoder: take a list of integers, output a string\n",
    "data = torch.tensor(encode(text), dtype=torch.long)\n",
    "\n",
    "# Let's now split up the data into train and validation sets\n",
    "n = int(0.9*len(data)) # first 90% will be train, rest val\n",
    "train_data = data[:n]\n",
    "val_data = data[n:]\n",
    "\n",
    "def get_batch(split, batch_size, block_size):\n",
    "    # generate a small batch of data of inputs x and targets y\n",
    "    data = train_data if split == 'train' else val_data\n",
    "    ix = torch.randint(len(data) - block_size, (batch_size,))\n",
    "    x = torch.stack([data[i:i+block_size] for i in ix])\n",
    "    y = torch.tensor([data[i + block_size] for i in ix])\n",
    "    # y = torch.stack([data[i+1:i+block_size+1] for i in ix])\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[53, 51, 64,  2, 41, 44,  1, 17],\n",
       "         [43,  2, 52, 40, 50, 44,  2, 59],\n",
       "         [44, 59,  2, 22, 58, 40, 41, 44],\n",
       "         [10,  2, 24, 22, 27, 20,  2, 21]]),\n",
       " tensor([44, 57, 51, 18]))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_batch('train', 4, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "block_size = 16\n",
    "\n",
    "class Flatten(nn.Module):\n",
    "    def __init__(self, n):\n",
    "        super(Flatten, self).__init__() \n",
    "        self.n = n\n",
    "\n",
    "    def __call__(self, x):\n",
    "        # print(x.shape)\n",
    "        B, T, C = x.shape\n",
    "        if T == self.n:\n",
    "            return  x.view(B, C * self.n)\n",
    "        return x.view(B, T//2, C * self.n)\n",
    "        out =  x.view(B, -1, C * self.n)\n",
    "        print(out.shape)\n",
    "        return out\n",
    "\n",
    "\n",
    "    def parameters(self):\n",
    "        return []\n",
    "\n",
    "class MLPModel(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.wte=nn.Embedding(config.vocab_size, config.n_embd, dtype=config.dtype, device=config.device)\n",
    "        self.flatten = nn.Flatten(1)\n",
    "        hidden = config.n_embd * block_size // 2\n",
    "        self.mlp1 = nn.Linear(config.n_embd * block_size, hidden)    \n",
    "        self.mlp2 = nn.Linear(hidden, hidden)    \n",
    "        self.lm_head = nn.Linear(hidden, vocab_size)\n",
    "\n",
    "    def forward(self, idx, targets=None):\n",
    "        x = self.wte(idx)  # token embeddings of shape (b, t, n_embd)\n",
    "        x = self.flatten(x)\n",
    "        x = self.mlp1(x)\n",
    "        x = self.mlp2(x)\n",
    "        logits = self.lm_head(x)\n",
    "        loss = None\n",
    "        if targets is not None:\n",
    "            # loss = F.cross_entropy(logits.view(-1, logits.size(-1)), targets.view(-1))\n",
    "            loss = F.cross_entropy(logits, targets)\n",
    "\n",
    "        return logits, loss        \n",
    "    \n",
    "\n",
    "class MLPModel2(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "\n",
    "        n_embd = config.n_embd\n",
    "        self.model = nn.Sequential(\n",
    "                    nn.Embedding(config.vocab_size, n_embd),\n",
    "                    Flatten(2), nn.Linear(n_embd * 2, n_embd * 2), nn.Tanh(),\n",
    "                    Flatten(2), nn.Linear(n_embd * 4, n_embd * 2), nn.Tanh(),\n",
    "                    Flatten(2), nn.Linear(n_embd * 4, n_embd * 2), nn.Tanh(),\n",
    "                    Flatten(2), nn.Linear(n_embd * 4, n_embd * 2), nn.Tanh(),\n",
    "                    nn.Linear(n_embd * 2, n_embd * 2),\n",
    "                    nn.Tanh(),\n",
    "                    nn.Linear(n_embd * 2, vocab_size))\n",
    "\n",
    "        # self.wte=nn.Embedding(config.vocab_size, config.n_embd, dtype=config.dtype, device=config.device)\n",
    "        # self.flatten = nn.Flatten(1)\n",
    "        # hidden = config.n_embd * block_size // 2\n",
    "        # self.mlp1 = nn.Linear(config.n_embd * block_size, hidden)    \n",
    "        # self.mlp2 = nn.Linear(hidden, hidden)    \n",
    "        # self.lm_head = nn.Linear(hidden, vocab_size)\n",
    "\n",
    "    def forward(self, idx, targets=None):\n",
    "        logits = self.model(idx)\n",
    "        # x = self.wte(idx)  # token embeddings of shape (b, t, n_embd)\n",
    "        # x = self.flatten(x)\n",
    "        # x = self.mlp1(x)\n",
    "        # x = self.mlp2(x)\n",
    "        # logits = self.lm_head(x)\n",
    "        loss = None\n",
    "        if targets is not None:\n",
    "            # loss = F.cross_entropy(logits.view(-1, logits.size(-1)), targets.view(-1))\n",
    "            loss = F.cross_entropy(logits, targets)\n",
    "\n",
    "        return logits, loss            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49568\n"
     ]
    }
   ],
   "source": [
    "# 26000 23.94s loss: 1.59636, train: 1.69068, val: 1.84234\n",
    "# parameter: 117360\n",
    "config = ModelArgs()\n",
    "config.vocab_size = vocab_size\n",
    "config.n_embd = 32\n",
    "config.n_layer = 4\n",
    "config.n_head = 4\n",
    "learning_rate = 1e-3\n",
    "batch_size = 16\n",
    "block_size = 16\n",
    "\n",
    "#  28000 53.24s loss: 1.59238, train: 1.60147, val: 1.75652\n",
    "#  304192\n",
    "# config.n_embd = 64\n",
    "# config.n_layer = 6\n",
    "\n",
    "#  26000 156.38s loss: 1.53036, train: 1.34517, val: 1.55875\n",
    "#  304192\n",
    "# block_size = 64\n",
    "model = GPT(config)\n",
    "\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def eval_mode(model, split):\n",
    "    model.eval()\n",
    "    xb, yb = get_batch(split, 1024 * 2, block_size)\n",
    "    logits, loss = model(xb, yb)\n",
    "    model.train()\n",
    "    return loss.item()\n",
    "\n",
    "print(sum(e.numel() for e in model.parameters()))\n",
    "\n",
    "#      0 0.97s loss: 4.14254, train: 4.12606, val: 4.12622\n",
    "#   2000 15.41s loss: 2.43846, train: 2.50690, val: 2.50940\n",
    "#   4000 15.87s loss: 2.45041, train: 2.38253, val: 2.45002\n",
    "#   6000 15.50s loss: 1.87670, train: 2.33288, val: 2.29257\n",
    "#   8000 16.25s loss: 2.40117, train: 2.25745, val: 2.21347\n",
    "#  10000 15.27s loss: 1.96440, train: 2.14363, val: 2.20197\n",
    "#  12000 15.40s loss: 2.25821, train: 2.12671, val: 2.15990\n",
    "#  14000 15.18s loss: 1.41092, train: 2.08953, val: 2.13023\n",
    "#  16000 15.21s loss: 1.61853, train: 2.00345, val: 2.10484\n",
    "#  18000 15.52s loss: 1.47404, train: 2.06662, val: 2.08309\n",
    "#  20000 15.36s loss: 2.22606, train: 2.09605, val: 2.07258\n",
    "#  22000 16.15s loss: 1.57381, train: 2.02398, val: 2.02660\n",
    "#  24000 16.62s loss: 2.39012, train: 2.01963, val: 2.09455\n",
    "#  26000 16.92s loss: 2.43945, train: 2.03690, val: 2.10079\n",
    "#  28000 15.43s loss: 1.67814, train: 2.00688, val: 2.08757\n",
    "#  30000 15.56s loss: 2.29863, train: 1.99688, val: 2.02595\n",
    "\n",
    "# above is attention. bellow is mlp\n",
    "\n",
    "#      0 0.01s loss: 1.86977, train: 2.19873, val: 2.28758\n",
    "#   2000 1.50s loss: 2.21103, train: 2.33470, val: 2.37905\n",
    "#   4000 1.52s loss: 1.96309, train: 2.25205, val: 2.36831\n",
    "#   6000 1.48s loss: 1.89688, train: 2.36085, val: 2.31879\n",
    "#   8000 1.46s loss: 2.42841, train: 2.29361, val: 2.38357\n",
    "#  10000 1.40s loss: 2.24522, train: 2.24002, val: 2.27659\n",
    "#  12000 1.51s loss: 2.24394, train: 2.17114, val: 2.24774\n",
    "#  14000 1.45s loss: 2.39240, train: 2.07881, val: 2.29540\n",
    "#  16000 1.48s loss: 2.45173, train: 2.23459, val: 2.23733\n",
    "#  18000 1.49s loss: 2.32054, train: 2.09277, val: 2.22561\n",
    "#  20000 1.86s loss: 2.58712, train: 2.12597, val: 2.26913\n",
    "#  22000 1.66s loss: 2.91778, train: 2.04940, val: 2.28270\n",
    "#  24000 1.64s loss: 1.76361, train: 2.06376, val: 2.24237\n",
    "#  26000 1.66s loss: 1.69099, train: 2.10229, val: 2.25317\n",
    "#  28000 1.50s loss: 1.59344, train: 2.10322, val: 2.25436\n",
    "#  30000 1.64s loss: 2.25858, train: 2.10492, val: 2.21290\n",
    "\n",
    "# # above wavenet\n",
    "#      0 0.01s loss: 4.23850, train: 4.17033, val: 4.17057\n",
    "#   2000 1.47s loss: 2.26062, train: 2.46871, val: 2.51698\n",
    "#   4000 1.39s loss: 2.17279, train: 2.34896, val: 2.32339\n",
    "#   6000 1.40s loss: 1.75408, train: 2.28589, val: 2.28735\n",
    "#   8000 1.42s loss: 2.64250, train: 2.17526, val: 2.21579\n",
    "#  10000 1.41s loss: 2.19711, train: 2.15487, val: 2.17959\n",
    "#  12000 1.42s loss: 2.06995, train: 2.06976, val: 2.08725\n",
    "#  14000 1.41s loss: 1.37480, train: 2.03400, val: 2.07191\n",
    "#  16000 1.44s loss: 2.39997, train: 2.06084, val: 2.00076\n",
    "#  18000 1.41s loss: 1.99309, train: 2.02796, val: 2.02401\n",
    "#  20000 1.41s loss: 1.52541, train: 2.01666, val: 2.08847\n",
    "#  22000 1.38s loss: 1.57991, train: 1.98687, val: 2.06349\n",
    "#  24000 1.39s loss: 1.96693, train: 1.97387, val: 1.96752\n",
    "#  26000 1.39s loss: 2.00294, train: 1.96320, val: 1.91582\n",
    "#  28000 1.41s loss: 2.25782, train: 1.94247, val: 2.00578\n",
    "#  30000 1.43s loss: 2.71035, train: 1.93993, val: 2.00118"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39490\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0.0130, -0.0244,  0.0519,  ..., -0.1142,  0.0245, -0.0126],\n",
       "         [-0.0093, -0.0133,  0.0367,  ..., -0.1408,  0.0179, -0.0367],\n",
       "         [ 0.0059, -0.0176,  0.1086,  ..., -0.1233,  0.0098, -0.0457],\n",
       "         ...,\n",
       "         [ 0.0048, -0.0396,  0.0417,  ..., -0.1158,  0.0273, -0.0483],\n",
       "         [ 0.0119, -0.0101,  0.0295,  ..., -0.1450, -0.0306,  0.0049],\n",
       "         [ 0.0098, -0.0077,  0.0573,  ..., -0.0993, -0.0086,  0.0459]],\n",
       "        grad_fn=<AddmmBackward0>),\n",
       " tensor(4.1754, grad_fn=<NllLossBackward0>))"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = MLPModel2(config)\n",
    "print(sum(e.numel() for e in model.parameters()))\n",
    "xb, yb = get_batch('train', batch_size, block_size)\n",
    "model(xb, yb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     0 0.01s loss: 4.23850, train: 4.17033, val: 4.17057\n",
      "  2000 1.47s loss: 2.26062, train: 2.46871, val: 2.51698\n",
      "  4000 1.39s loss: 2.17279, train: 2.34896, val: 2.32339\n",
      "  6000 1.40s loss: 1.75408, train: 2.28589, val: 2.28735\n",
      "  8000 1.42s loss: 2.64250, train: 2.17526, val: 2.21579\n",
      " 10000 1.41s loss: 2.19711, train: 2.15487, val: 2.17959\n",
      " 12000 1.42s loss: 2.06995, train: 2.06976, val: 2.08725\n",
      " 14000 1.41s loss: 1.37480, train: 2.03400, val: 2.07191\n",
      " 16000 1.44s loss: 2.39997, train: 2.06084, val: 2.00076\n",
      " 18000 1.41s loss: 1.99309, train: 2.02796, val: 2.02401\n",
      " 20000 1.41s loss: 1.52541, train: 2.01666, val: 2.08847\n",
      " 22000 1.38s loss: 1.57991, train: 1.98687, val: 2.06349\n",
      " 24000 1.39s loss: 1.96693, train: 1.97387, val: 1.96752\n",
      " 26000 1.39s loss: 2.00294, train: 1.96320, val: 1.91582\n",
      " 28000 1.41s loss: 2.25782, train: 1.94247, val: 2.00578\n",
      " 30000 1.43s loss: 2.71035, train: 1.93993, val: 2.00118\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "t = time.time()\n",
    "opti = torch.optim.AdamW(model.parameters(), learning_rate, fused=True)\n",
    "for step in range(30001):\n",
    "    for g in opti.param_groups:\n",
    "        if step > 20000: g['lr'] = learning_rate / 5\n",
    "        elif step > 10000: g['lr'] = learning_rate / 3\n",
    "\n",
    "    xb, yb = get_batch('train', batch_size, block_size)\n",
    "    logits, loss = model(xb, yb)\n",
    "    opti.zero_grad(set_to_none=True)\n",
    "    loss.backward()\n",
    "    opti.step()\n",
    "    if step % 2000 == 0:\n",
    "        n = time.time()\n",
    "        train_time = n - t\n",
    "        print(f'{step:6d} {train_time:.2f}s loss: {loss.item():.5f}, train: {eval_mode(model, \"train\"):.5f}, val: {eval_mode(model, \"val\"):.5f}')\n",
    "        t = n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.22320556640625\n"
     ]
    }
   ],
   "source": [
    "# 26000 23.94s loss: 1.59636, train: 1.69068, val: 1.84234\n",
    "# parameter: 117360\n",
    "config = ModelArgs()\n",
    "config.vocab_size = vocab_size\n",
    "config.n_embd = 64\n",
    "config.n_layer = 4\n",
    "config.n_head = 4\n",
    "config.dropout = 0.1\n",
    "config.rotary = True\n",
    "learning_rate = 1e-3\n",
    "batch_size = 64\n",
    "block_size = 128\n",
    "\n",
    "#  28000 53.24s loss: 1.59238, train: 1.60147, val: 1.75652\n",
    "#  304192\n",
    "# config.n_embd = 64\n",
    "# config.n_layer = 6\n",
    "\n",
    "#  26000 156.38s loss: 1.53036, train: 1.34517, val: 1.55875\n",
    "#  304192\n",
    "# block_size = 64\n",
    "model = GPT(config)\n",
    "# model = torch.compile(model)\n",
    "\n",
    "@torch.no_grad()\n",
    "def eval_mode(model, split):\n",
    "    model.eval()\n",
    "    xb, yb = get_batch(split, 1024 * 2, block_size)\n",
    "    logits, loss = model(xb, yb)\n",
    "    model.train()\n",
    "    return loss.item()\n",
    "\n",
    "print(sum(e.numel() for e in model.parameters()) / 1024 / 1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "t = time.time()\n",
    "opti = torch.optim.AdamW(model.parameters(), learning_rate)\n",
    "for step in range(10001):\n",
    "    for g in opti.param_groups:\n",
    "        if step > 20000: g['lr'] = learning_rate / 5\n",
    "        elif step > 10000: g['lr'] = learning_rate / 3\n",
    "\n",
    "    xb, yb = get_wk_batch(batch_size, block_size, config.device)\n",
    "    logits, loss = model(xb, yb)\n",
    "    opti.zero_grad(set_to_none=True)\n",
    "    loss.backward()\n",
    "    opti.step()\n",
    "    if step % 2000 == 0:\n",
    "        n = time.time()\n",
    "        train_time = n - t\n",
    "        print(f'{step:6d} {train_time:.2f}s loss: {loss.item():.5f}, train: {eval_mode(model, \"train\"):.5f}, val: {eval_mode(model, \"val\"):.5f}')\n",
    "        t = n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "t = time.time()\n",
    "opti = torch.optim.AdamW(model.parameters(), learning_rate * 0.5)\n",
    "for step in range(30001):\n",
    "    for g in opti.param_groups:\n",
    "        if step > 20000: g['lr'] = learning_rate / 5\n",
    "        elif step > 10000: g['lr'] = learning_rate / 3\n",
    "\n",
    "    xb, yb = get_batch('train', batch_size, block_size)\n",
    "    logits, loss = model(xb, yb)\n",
    "    opti.zero_grad(set_to_none=True)\n",
    "    loss.backward()\n",
    "    opti.step()\n",
    "    if step % 2000 == 0:\n",
    "        n = time.time()\n",
    "        train_time = n - t\n",
    "        print(f'{step:6d} {train_time:.2f}s loss: {loss.item():.5f}, train: {eval_mode(model, \"train\"):.5f}, val: {eval_mode(model, \"val\"):.5f}')\n",
    "        t = n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     0 0.12s loss: 4.20371, train: 4.10815, val: 4.10997\n",
      "  2000 22.33s loss: 2.16811, train: 2.12599, val: 2.16987\n",
      "  4000 19.42s loss: 2.17855, train: 1.98829, val: 2.06462\n",
      "  6000 21.77s loss: 1.99858, train: 1.90744, val: 2.01406\n",
      "  8000 20.54s loss: 2.08288, train: 1.87279, val: 1.99812\n",
      " 10000 19.68s loss: 1.82278, train: 1.84337, val: 1.95235\n",
      " 12000 19.88s loss: 1.85650, train: 1.77525, val: 1.92027\n",
      " 14000 23.85s loss: 1.95274, train: 1.76716, val: 1.90403\n",
      " 16000 20.85s loss: 1.89785, train: 1.75859, val: 1.91004\n",
      " 18000 19.18s loss: 1.95584, train: 1.74462, val: 1.88499\n",
      " 20000 18.84s loss: 1.91002, train: 1.74278, val: 1.88153\n",
      " 22000 22.03s loss: 1.66406, train: 1.71974, val: 1.86783\n",
      " 24000 18.64s loss: 1.92112, train: 1.70893, val: 1.87611\n",
      " 26000 18.82s loss: 1.77871, train: 1.70853, val: 1.85082\n",
      " 28000 18.50s loss: 1.59352, train: 1.69870, val: 1.86800\n",
      " 30000 18.73s loss: 1.91003, train: 1.70339, val: 1.84661\n"
     ]
    }
   ],
   "source": [
    "#  28000 27.25s loss: 1.66619, train: 1.67056, val: 1.81868\n",
    "\n",
    "import time\n",
    "t = time.time()\n",
    "opti = torch.optim.AdamW(model.parameters(), learning_rate)\n",
    "for step in range(30001):\n",
    "    for g in opti.param_groups:\n",
    "        if step > 20000: g['lr'] = learning_rate / 5\n",
    "        elif step > 10000: g['lr'] = learning_rate / 3\n",
    "\n",
    "    xb, yb = get_batch('train', batch_size, block_size)\n",
    "    logits, loss = model(xb, yb)\n",
    "    opti.zero_grad(set_to_none=True)\n",
    "    loss.backward()\n",
    "    opti.step()\n",
    "    if step % 2000 == 0:\n",
    "        n = time.time()\n",
    "        train_time = n - t\n",
    "        print(f'{step:6d} {train_time:.2f}s loss: {loss.item():.5f}, train: {eval_mode(model, \"train\"):.5f}, val: {eval_mode(model, \"val\"):.5f}')\n",
    "        t = n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def generate(model, idx, max_new_tokens, temperature=1.0, top_k=None):\n",
    "    \"\"\"\n",
    "    Take a conditioning sequence of indices idx (LongTensor of shape (b,t)) and complete\n",
    "    the sequence max_new_tokens times, feeding the predictions back into the model each time.\n",
    "    Most likely you'll want to make sure to be in model.eval() mode of operation for this.\n",
    "    \"\"\"\n",
    "    for _ in range(max_new_tokens):\n",
    "        # if the sequence context is growing too long we must crop it at block_size\n",
    "        idx_cond = idx if idx.size(1) <= block_size else idx[:, -block_size:]\n",
    "        # forward the model to get the logits for the index in the sequence\n",
    "        logits, _ = model(idx_cond)\n",
    "        # pluck the logits at the final step and scale by desired temperature\n",
    "        logits = logits[:, -1, :] / temperature\n",
    "        # optionally crop the logits to only the top k options\n",
    "        if top_k is not None:\n",
    "            v, _ = torch.topk(logits, min(top_k, logits.size(-1)))\n",
    "            logits[logits < v[:, [-1]]] = -float('Inf')\n",
    "        # apply softmax to convert logits to (normalized) probabilities\n",
    "        probs = F.softmax(logits, dim=-1)\n",
    "        # sample from the distribution\n",
    "        idx_next = torch.multinomial(probs, num_samples=1)\n",
    "        # append sampled index to the running sequence and continue\n",
    "        idx = torch.cat((idx, idx_next), dim=1)\n",
    "    return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<>he my comfore of ous sweet not much should of tuken a stoold.\n",
      "\n",
      "Fisters then have sulf minince so cha\n"
     ]
    }
   ],
   "source": [
    "print(decode(generate(model, idx = torch.zeros((1, 1), dtype=torch.long), max_new_tokens=100)[0].tolist()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    #  with rotary\n",
    "     0 0.03s loss: 4.24567, train: 4.09009, val: 4.09109\n",
    "  1000 25.91s loss: 1.68743, train: 1.63288, val: 1.78919\n",
    "  2000 25.88s loss: 1.53839, train: 1.46762, val: 1.64870\n",
    "  3000 25.79s loss: 1.47733, train: 1.40543, val: 1.59762\n",
    "  4000 26.56s loss: 1.47561, train: 1.37177, val: 1.56717\n",
    "  5000 26.36s loss: 1.42775, train: 1.35312, val: 1.55640\n",
    "  6000 25.83s loss: 1.41559, train: 1.32865, val: 1.54277\n",
    "  7000 25.83s loss: 1.39557, train: 1.32097, val: 1.52121\n",
    "  8000 25.54s loss: 1.39905, train: 1.30683, val: 1.53706\n",
    "  9000 26.02s loss: 1.40830, train: 1.30955, val: 1.51410\n",
    " 10000 25.89s loss: 1.40223, train: 1.29421, val: 1.52741\n",
    " 11000 25.19s loss: 1.40270, train: 1.29250, val: 1.51724\n",
    " 12000 26.01s loss: 1.33441, train: 1.29159, val: 1.52723\n",
    " 13000 26.52s loss: 1.35442, train: 1.25828, val: 1.49880\n",
    " 14000 26.40s loss: 1.32233, train: 1.25585, val: 1.50987\n",
    " 15000 26.66s loss: 1.35553, train: 1.25042, val: 1.49551\n",
    " 16000 27.02s loss: 1.33569, train: 1.24887, val: 1.49686\n",
    " 17000 26.28s loss: 1.33931, train: 1.25006, val: 1.49716\n",
    " 18000 25.27s loss: 1.36694, train: 1.25032, val: 1.49718\n",
    " 19000 26.49s loss: 1.31716, train: 1.24690, val: 1.49094\n",
    " 20000 26.55s loss: 1.37013, train: 1.25256, val: 1.48834\n",
    "\n",
    "# 26000 23.94s loss: 1.59636, train: 1.69068, val: 1.84234\n",
    "# parameter: 117360\n",
    "config = ModelArgs()\n",
    "config.vocab_size = vocab_size\n",
    "config.n_embd = 64\n",
    "config.n_layer = 4\n",
    "config.n_head = 4\n",
    "config.dropout = 0.1\n",
    "config.rotary = False\n",
    "learning_rate = 1e-3\n",
    "batch_size = 64\n",
    "block_size = 128\n",
    "\n",
    "#  28000 53.24s loss: 1.59238, train: 1.60147, val: 1.75652\n",
    "#  304192\n",
    "# config.n_embd = 64\n",
    "# config.n_layer = 6\n",
    "\n",
    "#  26000 156.38s loss: 1.53036, train: 1.34517, val: 1.55875\n",
    "#  304192\n",
    "# block_size = 64\n",
    "model = GPT(config)\n",
    "# model = torch.compile(model)\n",
    "\n",
    "@torch.no_grad()\n",
    "def eval_mode(model, split):\n",
    "    model.eval()\n",
    "    xb, yb = get_batch(split, 1024 * 2, block_size)\n",
    "    logits, loss = model(xb, yb)\n",
    "    model.train()\n",
    "    return loss.item()\n",
    "\n",
    "print(sum(e.numel() for e in model.parameters()) / 1024 / 1024)\n",
    "\n",
    "\n",
    "# no rotary\n",
    "     0 0.04s loss: 4.20762, train: 4.03342, val: 4.03646\n",
    "  1000 23.65s loss: 1.88716, train: 1.79410, val: 1.92691\n",
    "  2000 23.82s loss: 1.66935, train: 1.56973, val: 1.76726\n",
    "  3000 24.01s loss: 1.59561, train: 1.48337, val: 1.67860\n",
    "  4000 24.11s loss: 1.54473, train: 1.43455, val: 1.62868\n",
    "  5000 23.89s loss: 1.49493, train: 1.40338, val: 1.59355\n",
    "  6000 23.99s loss: 1.46876, train: 1.37792, val: 1.58696\n",
    "  7000 23.51s loss: 1.46747, train: 1.37471, val: 1.58601\n",
    "  8000 23.38s loss: 1.47176, train: 1.35034, val: 1.56929\n",
    "  9000 22.87s loss: 1.44583, train: 1.34326, val: 1.57503\n",
    " 10000 23.65s loss: 1.44932, train: 1.33792, val: 1.55838\n",
    " 11000 23.95s loss: 1.40971, train: 1.32840, val: 1.55533\n",
    " 12000 24.01s loss: 1.42878, train: 1.31682, val: 1.54599\n",
    " 13000 23.26s loss: 1.40214, train: 1.29594, val: 1.53102\n",
    " 14000 23.75s loss: 1.37013, train: 1.28887, val: 1.53773\n",
    " 15000 23.31s loss: 1.38122, train: 1.28983, val: 1.52035\n",
    " 16000 23.83s loss: 1.34553, train: 1.28327, val: 1.52100\n",
    " 17000 23.41s loss: 1.39873, train: 1.27728, val: 1.52637\n",
    " 18000 23.08s loss: 1.40726, train: 1.27376, val: 1.52361\n",
    " 19000 22.95s loss: 1.35267, train: 1.28464, val: 1.51774\n",
    " 20000 23.35s loss: 1.36085, train: 1.26649, val: 1.53216"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: http://mirrors.aliyun.com/pypi/simple/\n",
      "Collecting pandas\n",
      "  Downloading http://mirrors.aliyun.com/pypi/packages/e1/0c/ad295fd74bfac85358fd579e271cded3ac969de81f62dd0142c426b9da91/pandas-2.2.3-cp312-cp312-macosx_11_0_arm64.whl (11.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.4/11.4 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting pyarrow\n",
      "  Downloading http://mirrors.aliyun.com/pypi/packages/6a/50/12829e7111b932581e51dda51d5cb39207a056c30fe31ef43f14c63c4d7e/pyarrow-18.1.0-cp312-cp312-macosx_12_0_arm64.whl (29.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m29.5/29.5 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.26.0 in ./.venv/lib/python3.12/site-packages (from pandas) (2.2.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./.venv/lib/python3.12/site-packages (from pandas) (2.9.0.post0)\n",
      "Collecting pytz>=2020.1 (from pandas)\n",
      "  Downloading http://mirrors.aliyun.com/pypi/packages/11/c3/005fcca25ce078d2cc29fd559379817424e94885510568bc1bc53d7d5846/pytz-2024.2-py2.py3-none-any.whl (508 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas)\n",
      "  Downloading http://mirrors.aliyun.com/pypi/packages/a6/ab/7e5f53c3b9d14972843a647d8d7a853969a58aecc7559cb3267302c94774/tzdata-2024.2-py2.py3-none-any.whl (346 kB)\n",
      "Requirement already satisfied: six>=1.5 in ./.venv/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Installing collected packages: pytz, tzdata, pyarrow, pandas\n",
      "Successfully installed pandas-2.2.3 pyarrow-18.1.0 pytz-2024.2 tzdata-2024.2\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas pyarrow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all pretraining:  10393085\n",
      "all shake data:   1115394\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pyarrow.parquet as pq\n",
    "\n",
    "file =  '/Users/admin/workspace/nn2/train-00000-of-00001.parquet'\n",
    "table = pq.read_table(file)\n",
    "\n",
    "wk_chars = set()\n",
    "all_txts = []\n",
    "for i in table.to_pylist():\n",
    "    txt = i['text'].strip()\n",
    "    if len(txt) > 130:\n",
    "        cs = set(txt)\n",
    "        wk_chars.update(cs)\n",
    "        all_txts.append(txt)\n",
    "\n",
    "wk_chars.add('\\n')\n",
    "u_chars = sorted(list(wk_chars))\n",
    "import math\n",
    "vocab_size = math.ceil((len(u_chars) + 1) / 32) * 32 #\n",
    "# create a mapping from characters to integers\n",
    "stoi = { ch:i + 1 for i,ch in enumerate(u_chars) }\n",
    "stoi['<>'] = 0\n",
    "itos = { i:ch for ch,i in stoi.items() }\n",
    "encode = lambda s: [stoi[c] for c in s] # encoder: take a string, output a list of integers\n",
    "decode = lambda l: ''.join([itos[i] for i in l]) # decoder: take a list of integers, output a string\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "wk_data = []\n",
    "for txt in all_txts:\n",
    "    data = torch.tensor(encode(txt), dtype=torch.long)\n",
    "    wk_data.append(data)\n",
    "\n",
    "print('all pretraining: ', sum(len(d) for d in wk_data))\n",
    "\n",
    "import random\n",
    "def get_wk_batch(batch_size, block_size, device):\n",
    "    # generate a small batch of data of inputs x and targets y\n",
    "    ix = torch.randint(len(wk_data), (batch_size,))\n",
    "\n",
    "    xs, ys = [], []\n",
    "    for i in ix:\n",
    "        d = wk_data[i]\n",
    "        idx = random.randint(0, len(d) - block_size - 1)\n",
    "        xs.append(d[idx:idx+block_size])\n",
    "        ys.append(d[idx+1:idx+1+block_size])\n",
    "    return torch.stack(xs).to(device), torch.stack(ys).to(device)\n",
    "\n",
    "with open('input.txt', 'r', encoding='utf-8') as f:\n",
    "    text = f.read()\n",
    "data = torch.tensor(encode(text), dtype=torch.long).to(device)\n",
    "print('all shake data:  ', len(data))\n",
    "\n",
    "# Let's now split up the data into train and validation sets\n",
    "n = int(0.9*len(data)) # first 90% will be train, rest val\n",
    "train_data = data[:n]\n",
    "val_data = data[n:]\n",
    "\n",
    "def get_batch(split, batch_size, block_size):\n",
    "    # generate a small batch of data of inputs x and targets y\n",
    "    data = train_data if split == 'train' else val_data\n",
    "    ix = torch.randint(len(data) - block_size, (batch_size,))\n",
    "    x = torch.stack([data[i:i+block_size] for i in ix])\n",
    "    y = torch.stack([data[i+1:i+block_size+1] for i in ix])\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "288"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([12012, 128]), torch.Size([12012, 128]), 14947)"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x, y = get_wk_batch(12012, 128, 'cpu')\n",
    "x.shape, y.shape, len(wk_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39490"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_embd = 32\n",
    "model = nn.Sequential(\n",
    "            nn.Embedding(config.vocab_size, n_embd),\n",
    "            Flatten(2), nn.Linear(n_embd * 2, n_embd * 2), nn.Tanh(),\n",
    "            Flatten(2), nn.Linear(n_embd * 4, n_embd * 2), nn.Tanh(),\n",
    "            Flatten(2), nn.Linear(n_embd * 4, n_embd * 2), nn.Tanh(),\n",
    "            Flatten(2), nn.Linear(n_embd * 4, n_embd * 2), nn.Tanh(),\n",
    "            nn.Linear(n_embd * 2, n_embd * 2),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(n_embd * 2, vocab_size)\n",
    "        )\n",
    "\n",
    "x, y = get_batch('train', batch_size, block_size)\n",
    "\n",
    "# model = nn.Embedding(config.vocab_size, config.n_embd)\n",
    "\n",
    "x = model(x)\n",
    "x.shape\n",
    "\n",
    "sum(p.numel() for p in model.parameters())\n",
    "# f = Flatten(2)\n",
    "# f2 = nn.Linear(n_embd * 2, n_embd * 2)\n",
    "# f2(f(x))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
